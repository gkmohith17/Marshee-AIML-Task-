{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_recall_curve\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import joblib\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "#  Data Loading and Exploration\n",
    "#dummy\n",
    "def generate_sample_data(n_samples=10000):\n",
    "  \n",
    "    timestamps = pd.date_range(start='2025-01-01', periods=n_samples, freq='100ms')\n",
    "    \n",
    "   \n",
    "    activities = ['walking', 'running', 'resting', 'playing']\n",
    "    activity_labels = np.random.choice(activities, size=n_samples, \n",
    "                                     p=[0.4, 0.2, 0.3, 0.1])  \n",
    "    \n",
    "\n",
    "    acc_x, acc_y, acc_z = [], [], []\n",
    "    \n",
    "    for activity in activity_labels:\n",
    "        if activity == 'walking':\n",
    "            acc_x.append(np.sin(np.random.rand() * np.pi) + np.random.normal(0, 0.2))\n",
    "            acc_y.append(np.cos(np.random.rand() * np.pi) + np.random.normal(0, 0.3))\n",
    "            acc_z.append(np.sin(np.random.rand() * np.pi) + np.random.normal(0, 0.2))\n",
    "        elif activity == 'running':\n",
    "            acc_x.append(1.5 * np.sin(np.random.rand() * np.pi) + np.random.normal(0, 0.4))\n",
    "            acc_y.append(1.5 * np.cos(np.random.rand() * np.pi) + np.random.normal(0, 0.5))\n",
    "            acc_z.append(1.8 * np.sin(np.random.rand() * np.pi) + np.random.normal(0, 0.3))\n",
    "        elif activity == 'resting':\n",
    "            acc_x.append(np.random.normal(0, 0.1))\n",
    "            acc_y.append(np.random.normal(0, 0.1))\n",
    "            acc_z.append(np.random.normal(0, 0.1))\n",
    "        else:  \n",
    "            acc_x.append(np.random.normal(0, 0.8))\n",
    "            acc_y.append(np.random.normal(0, 0.8))\n",
    "            acc_z.append(np.random.normal(0, 0.8))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'acc_x': acc_x,\n",
    "        'acc_y': acc_y,\n",
    "        'acc_z': acc_z,\n",
    "        'activity': activity_labels\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate and display sample data\n",
    "df = generate_sample_data()\n",
    "print(f\"Generated dataset shape: {df.shape}\")\n",
    "print(\"\\nSample data:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nActivity distribution:\")\n",
    "print(df['activity'].value_counts())\n",
    "\n",
    "\n",
    "#  Data Preprocessing\n",
    "\n",
    "def preprocess_data(df):\n",
    "    # Detect and handle outliers\n",
    "    z_scores = stats.zscore(df[['acc_x', 'acc_y', 'acc_z']])\n",
    "    abs_z_scores = np.abs(z_scores)\n",
    "    filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "    df_filtered = df[filtered_entries]\n",
    "    \n",
    "    print(f\"Removed {len(df) - len(df_filtered)} outliers\")\n",
    "    \n",
    "    # Apply low-pass filter to remove high-frequency noise\n",
    "    def butter_lowpass_filter(data, cutoff=3.0, fs=10.0, order=2):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        y = filtfilt(b, a, data)\n",
    "        return y\n",
    "    \n",
    "    # Apply filter to each accelerometer axis\n",
    "    for axis in ['acc_x', 'acc_y', 'acc_z']:\n",
    "        df_filtered[f\"{axis}_filtered\"] = butter_lowpass_filter(df_filtered[axis].values)\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Apply preprocessing\n",
    "df_clean = preprocess_data(df)\n",
    "print(\"\\nCleaned data sample:\")\n",
    "print(df_clean.head())\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "\n",
    "def create_features(df, window_size=20):\n",
    "    \"\"\"Extract features from accelerometer data using sliding windows\"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "\n",
    "    for i in range(0, len(df) - window_size, window_size // 2):  # 50% overlap\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        \n",
    "  \n",
    "        if len(window['activity'].unique()) > 1:\n",
    "            continue\n",
    "     \n",
    "        feature_row = {}\n",
    "        \n",
    "        for axis in ['acc_x_filtered', 'acc_y_filtered', 'acc_z_filtered']:\n",
    "            # Basic statistics\n",
    "            feature_row[f'{axis}_mean'] = window[axis].mean()\n",
    "            feature_row[f'{axis}_std'] = window[axis].std()\n",
    "            feature_row[f'{axis}_max'] = window[axis].max()\n",
    "            feature_row[f'{axis}_min'] = window[axis].min()\n",
    "            feature_row[f'{axis}_range'] = window[axis].max() - window[axis].min()\n",
    "            feature_row[f'{axis}_median'] = window[axis].median()\n",
    "            \n",
    "            # Higher order statistics\n",
    "            feature_row[f'{axis}_skew'] = window[axis].skew()\n",
    "            feature_row[f'{axis}_kurtosis'] = window[axis].kurtosis()\n",
    "            \n",
    "            # Signal dynamics\n",
    "            feature_row[f'{axis}_rms'] = np.sqrt(np.mean(np.square(window[axis])))\n",
    "            \n",
    "            # Zero crossings\n",
    "            zero_crossings = np.where(np.diff(np.signbit(window[axis])))[0]\n",
    "            feature_row[f'{axis}_zero_crossings'] = len(zero_crossings)\n",
    "        \n",
    "        # Cross-axis features\n",
    "        feature_row['correlation_xy'] = window['acc_x_filtered'].corr(window['acc_y_filtered'])\n",
    "        feature_row['correlation_xz'] = window['acc_x_filtered'].corr(window['acc_z_filtered'])\n",
    "        feature_row['correlation_yz'] = window['acc_y_filtered'].corr(window['acc_z_filtered'])\n",
    "        \n",
    "        # Magnitude features\n",
    "        magnitude = np.sqrt(window['acc_x_filtered']**2 + \n",
    "                           window['acc_y_filtered']**2 + \n",
    "                           window['acc_z_filtered']**2)\n",
    "        \n",
    "        feature_row['magnitude_mean'] = magnitude.mean()\n",
    "        feature_row['magnitude_std'] = magnitude.std()\n",
    "        feature_row['magnitude_max'] = magnitude.max()\n",
    "        \n",
    "        features.append(feature_row)\n",
    "        \n",
    "        labels.append(window['activity'].mode()[0])\n",
    "    \n",
    "    feature_df = pd.DataFrame(features)\n",
    "    \n",
    "    return feature_df, labels\n",
    "\n",
    "# Extract features\n",
    "X, y = create_features(df_clean)\n",
    "print(f\"\\nExtracted {X.shape[1]} features from {X.shape[0]} windows\")\n",
    "print(\"\\nFeature sample:\")\n",
    "print(X.head())\n",
    "\n",
    "# Data Splitting and Scaling\n",
    "\n",
    "# Split into train, validation and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for deployment\n",
    "joblib.dump(scaler, 'marshee_feature_scaler.pkl')\n",
    "\n",
    "# Feature Selection\n",
    "\n",
    "# Train a base model to use for feature selection\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "base_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Select features based on importance\n",
    "feature_selector = SelectFromModel(base_rf, threshold=\"mean\")\n",
    "feature_selector.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Apply feature selection\n",
    "X_train_selected = feature_selector.transform(X_train_scaled)\n",
    "X_val_selected = feature_selector.transform(X_val_scaled)\n",
    "X_test_selected = feature_selector.transform(X_test_scaled)\n",
    "\n",
    "print(f\"\\nSelected {X_train_selected.shape[1]} out of {X_train_scaled.shape[1]} features\")\n",
    "\n",
    "# Get selected feature names for interpretation\n",
    "selected_indices = feature_selector.get_support(indices=True)\n",
    "selected_features = X.columns[selected_indices]\n",
    "print(\"\\nTop selected features:\")\n",
    "print(selected_features.tolist())\n",
    "\n",
    "# Model Training and Hyperparameter Tuning\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Set up K-fold cross-validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=cv,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "print(\"\\nPerforming grid search for hyperparameter tuning...\")\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf = grid_search.best_estimator_\n",
    "best_rf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Save model for deployment\n",
    "joblib.dump(best_rf, 'marshee_activity_classifier.pkl')\n",
    "joblib.dump(feature_selector, 'marshee_feature_selector.pkl')\n",
    "\n",
    "# Model Evaluation\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X, y, dataset_name):\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    recall = recall_score(y, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    \n",
    "    return accuracy, f1, cm, y_pred\n",
    "\n",
    "# Evaluate on training set\n",
    "train_accuracy, train_f1, train_cm, train_pred = evaluate_model(\n",
    "    best_rf, X_train_selected, y_train, \"Training Set\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_accuracy, val_f1, val_cm, val_pred = evaluate_model(\n",
    "    best_rf, X_val_selected, y_val, \"Validation Set\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy, test_f1, test_cm, test_pred = evaluate_model(\n",
    "    best_rf, X_test_selected, y_test, \"Test Set\")\n",
    "\n",
    "# Visualization\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(cm, classes, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Get class labels\n",
    "class_labels = np.unique(y)\n",
    "\n",
    "# Plot confusion matrix for test set\n",
    "cm_plot = plot_confusion_matrix(test_cm, class_labels, 'Confusion Matrix - Test Set')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "\n",
    "# Feature importance plot\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    # Sort feature importances in descending order\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Rearrange feature names so they match the sorted feature importances\n",
    "    names = [feature_names[i] for i in indices]\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Feature Importance\")\n",
    "    plt.bar(range(X_train_selected.shape[1]), importances[indices])\n",
    "    plt.xticks(range(X_train_selected.shape[1]), names, rotation=90)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return plt\n",
    "\n",
    "# Plot feature importance\n",
    "importance_plot = plot_feature_importance(best_rf, selected_features)\n",
    "plt.savefig('feature_importance.png')\n",
    "\n",
    "# Model Conversion for Deployment\n",
    "\n",
    "# Create a simplified model for on-device deployment\n",
    "# In a real scenario, we would use TensorFlow Lite or similar\n",
    "\n",
    "# Select top 10 features for a lighter model\n",
    "top_n_features = 10\n",
    "top_feature_indices = np.argsort(best_rf.feature_importances_)[::-1][:top_n_features]\n",
    "\n",
    "# Train a smaller model with fewer estimators and only top features\n",
    "deployment_model = RandomForestClassifier(n_estimators=50, \n",
    "                                          max_depth=10,\n",
    "                                          random_state=42)\n",
    "\n",
    "# Get indices of top features in the original feature set\n",
    "top_features_in_original = [selected_indices[i] for i in top_feature_indices]\n",
    "X_train_deployment = X_train_scaled[:, top_features_in_original]\n",
    "X_test_deployment = X_test_scaled[:, top_features_in_original]\n",
    "\n",
    "# Train the deployment model\n",
    "deployment_model.fit(X_train_deployment, y_train)\n",
    "\n",
    "# Evaluate deployment model\n",
    "print(\"\\nEvaluating lightweight deployment model:\")\n",
    "deploy_accuracy, deploy_f1, deploy_cm, deploy_pred = evaluate_model(\n",
    "    deployment_model, X_test_deployment, y_test, \"Deployment Model (Test Set)\")\n",
    "\n",
    "# Save deployment model\n",
    "joblib.dump(deployment_model, 'marshee_deployment_model.pkl')\n",
    "joblib.dump(top_features_in_original, 'marshee_deployment_feature_indices.pkl')\n",
    "\n",
    "# 10. Real-time Inference Simulation\n",
    "\n",
    "def simulate_realtime_processing(raw_data, window_size=20, overlap=10):\n",
    "    \"\"\"Simulate real-time processing of accelerometer data\"\"\"\n",
    "    # Apply preprocessing to raw data\n",
    "    processed_data = preprocess_data(raw_data)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process data in overlapping windows\n",
    "    for i in range(0, len(processed_data) - window_size, overlap):\n",
    "        # Extract window\n",
    "        window = processed_data.iloc[i:i+window_size]\n",
    "        \n",
    "        # Extract features (simplified for demonstration)\n",
    "        window_features = {}\n",
    "        \n",
    "        for axis in ['acc_x_filtered', 'acc_y_filtered', 'acc_z_filtered']:\n",
    "            window_features[f'{axis}_mean'] = window[axis].mean()\n",
    "            window_features[f'{axis}_std'] = window[axis].std()\n",
    "            # Add other feature extraction here...\n",
    "        \n",
    "        # Convert to DataFrame and align with training features\n",
    "        features_df = pd.DataFrame([window_features])\n",
    "        aligned_features = pd.DataFrame(columns=X.columns)\n",
    "        for col in features_df.columns:\n",
    "            if col in aligned_features.columns:\n",
    "                aligned_features[col] = features_df[col]\n",
    "        \n",
    "        aligned_features = aligned_features.fillna(0)\n",
    "        \n",
    "        # Scale features\n",
    "        scaled_features = scaler.transform(aligned_features)\n",
    "        \n",
    "        # Select only the features needed for the deployment model\n",
    "        selected_features = scaled_features[:, top_features_in_original]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = deployment_model.predict(selected_features)[0]\n",
    "        probability = np.max(deployment_model.predict_proba(selected_features)[0])\n",
    "        \n",
    "        # Store result\n",
    "        results.append({\n",
    "            'start_time': window.iloc[0]['timestamp'],\n",
    "            'end_time': window.iloc[-1]['timestamp'],\n",
    "            'prediction': prediction,\n",
    "            'confidence': probability\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Generate some new raw data to simulate real-time processing\n",
    "new_raw_data = generate_sample_data(1000)\n",
    "\n",
    "# Simulate real-time processing\n",
    "print(\"\\nSimulating real-time processing...\")\n",
    "realtime_results = simulate_realtime_processing(new_raw_data)\n",
    "print(\"\\nReal-time processing results:\")\n",
    "print(realtime_results.head())\n",
    "\n",
    "# 11. Summary and Final Metrics\n",
    "z\n",
    "print(\"\\n===== Model Performance Summary =====\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}, F1: {train_f1:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, F1: {test_f1:.4f}\")\n",
    "print(f\"Deployment Model Test Accuracy: {deploy_accuracy:.4f}, F1: {deploy_f1:.4f}\")\n",
    "print(f\"Selected Features: {X_train_selected.shape[1]} out of {X_train_scaled.shape[1]}\")\n",
    "print(f\"Deployment Model Features: {top_n_features}\")\n",
    "print(\"\\nModel training and evaluation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
